{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c5d91c",
   "metadata": {},
   "source": [
    "### Importing and Installing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5be2ebe",
   "metadata": {},
   "source": [
    "### Importing Datsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559496b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"\", split=\"train\", streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e395fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 50000\n",
    "\n",
    "samples = []\n",
    "for i, sample in enumerate(dataset):\n",
    "    if i >= num_samples:\n",
    "        break\n",
    "    instruction = sample[\"Question\"]\n",
    "    output = sample[\"Answer\"]\n",
    "    formatted = {\n",
    "        \"text\": f\"<|im_start|>user\\n{instruction}<|im_end|>\\n<|im_start|>assistant\\n{output}<|im_end|>\"\n",
    "    }\n",
    "    samples.append(formatted)\n",
    "\n",
    "import json\n",
    "with open(\"GeneralKnowledge.jsonl\", \"w\") as f:\n",
    "    for item in samples:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2f7c4",
   "metadata": {},
   "source": [
    "#### Concatinate jsonl files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f891efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"Datasets/dummy1.jsonl\",\n",
    "    \"Datasets/dummy2.jsonl\",\n",
    "    \"Datasets/dummy3.jsonl\"\n",
    "]\n",
    "\n",
    "all_data = []\n",
    "\n",
    "for file in files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            all_data.append(json.loads(line))\n",
    "\n",
    "random.shuffle(all_data)\n",
    "\n",
    "with open(\"Instruct_Dataset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in all_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Combined {len(files)} files into 'Instruct_Dataset.jsonl' with {len(all_data)} entries.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
